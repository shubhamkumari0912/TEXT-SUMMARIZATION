from transformers import pipeline
import requests
import time

# Explicitly specify the summarization model
summarizer = pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")

# Function to fetch live data from a news API
def fetch_live_data(url):
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        # Only keep articles with non-empty content
        articles = [article["content"] for article in data["articles"] if "content" in article and article["content"]]
        return articles
    else:
        print("Failed to fetch data. Status code:", response.status_code)
        return []

# Function to summarize live data
def summarize_texts(texts):
    summaries = []
    for text in texts:
        # Dynamically set max_length and min_length based on input length
        input_length = len(text.split())
        max_len = min(50, int(0.8 * input_length))
        min_len = max(20, int(0.5 * input_length))

        summary = summarizer(text, max_length=max_len, min_length=min_len, do_sample=False)
        summaries.append(summary[0]["summary_text"])
    return summaries

# Replace this URL with a valid news API endpoint and your API key
news_api_url = "https://newsapi.org/v2/top-headlines?country=us&apiKey=9fb0d6424b5b413baa7e79c9efe550a9"

# Fetch and summarize new data every 10 minutes
while True:
    print("Fetching live data...")
    texts = fetch_live_data(news_api_url)
    if texts:
        summaries = summarize_texts(texts)
        for i, summary in enumerate(summaries):
            print(f"Article {i + 1} Summary:\n", summary, "\n")
    else:
        print("No new articles found.")

    # Wait for 10 minutes before fetching new data
    time.sleep(600)
